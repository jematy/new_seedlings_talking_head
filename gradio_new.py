import gradio as gr
import subprocess
import os
import shutil
import uuid
import re
import tempfile
from subprocess import Popen, PIPE

MODEL_ROOT = "/data/new_seedlings/model"
DATA_ROOT = "data"

# === å·¥å…·å‡½æ•° ===
def list_model_names():
    return [d for d in os.listdir(MODEL_ROOT) if os.path.isdir(os.path.join(MODEL_ROOT, d))]

def list_processed_ids():
    return [d for d in os.listdir(DATA_ROOT) if os.path.isdir(os.path.join(DATA_ROOT, d))]

def get_reference_image(model_name):
    validation_path = os.path.join(MODEL_ROOT, model_name, "validation")
    if not os.path.exists(validation_path):
        return None

    pattern = r"ngp_ep(\d{4})_(\d{4})_rgb\.png"
    candidates = []

    for fname in os.listdir(validation_path):
        match = re.match(pattern, fname)
        if match:
            ep = int(match.group(1))
            frame = int(match.group(2))
            candidates.append((ep, frame, fname))

    if not candidates:
        return None

    max_ep = max(c[0] for c in candidates)
    filtered = [c for c in candidates if c[0] == max_ep]
    selected = max(filtered, key=lambda x: x[1])

    return os.path.join(validation_path, selected[2])

def update_reference_image(model_name):
    return get_reference_image(model_name)

# ========== è¯­éŸ³ç”Ÿæˆ ==========
def process_audio_with_log(audio_file, model_name):
    audio_path = f"/tmp/{uuid.uuid4()}.wav"
    shutil.copy(audio_file, audio_path)

    workspace = os.path.join(MODEL_ROOT, model_name)
    output_dir = os.path.join(workspace, "results")
    if os.path.exists(output_dir):
        shutil.rmtree(output_dir)

    command = [
        "python", "main.py", "data/jkx",
        "--workspace", workspace,
        "-O", "--torso", "--test", "--test_train",
        "--asr_model", "ave",
        "--aud", audio_path,
        "--au45"
    ]

    log = "ğŸš€ å¼€å§‹ç”Ÿæˆè§†é¢‘...\n"

    try:
        process = Popen(command, stdout=PIPE, stderr=PIPE, text=True)
        for line in process.stdout:
            log += line
            yield log, None
        process.wait()
        if process.returncode != 0:
            raise Exception("å‘½ä»¤è¿è¡Œå¤±è´¥")
    except Exception as e:
        log += f"\nâŒ å‡ºé”™ï¼š{e}"
        yield log, None
        return

    if not os.path.exists(output_dir):
        log += "\nâŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨"
        yield log, None
        return

    for fname in os.listdir(output_dir):
        if fname.endswith("_audio.mp4"):
            video_path = os.path.join(output_dir, fname)
            log += f"\nâœ… ç”ŸæˆæˆåŠŸï¼š{fname}"
            yield log, video_path
            return

    log += "\nâŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶"
    yield log, None


# ========== æ­¥éª¤ 1ï¼šå¤„ç†æ•°æ® ==========
def handle_data_processing_with_log(video_file, user_id):
    if not user_id:
        yield "âŒ è¯·è¾“å…¥ ID"
        return

    user_dir = os.path.join(DATA_ROOT, user_id)
    os.makedirs(user_dir, exist_ok=True)
    video_target = os.path.join(user_dir, f"{user_id}.mp4")
    shutil.copy(video_file, video_target)

    command = ["python", "data_utils/process.py", video_target, "--asr", "ave"]

    log = f"ğŸ“¦ å¼€å§‹å¤„ç†è§†é¢‘ï¼š{user_id}.mp4\n"

    try:
        process = Popen(command, stdout=PIPE, stderr=PIPE, text=True)
        for line in process.stdout:
            log += line
            yield log
        process.wait()
        if process.returncode != 0:
            raise Exception("å¤„ç†å¤±è´¥")
    except Exception as e:
        log += f"\nâŒ é”™è¯¯ï¼š{e}"
        yield log
        return

    log += "\nâœ… æ•°æ®å¤„ç†å®Œæˆï¼"
    yield log

# ========== æ­¥éª¤ 2ï¼šè®­ç»ƒæ¨¡å‹ ==========
def train_model(user_id, use_portrait):
    if not user_id:
        yield "âŒ è¯·é€‰æ‹©ä¸€ä¸ªå·²å¤„ç†çš„ ID", gr.update()

    workspace = f"model/trial_{user_id}"
    cmd = [
        "python", "main.py", f"data/{user_id}",
        "--workspace", workspace,
        "-O", "--test", "--asr_model", "ave"
    ]
    if use_portrait:
        cmd.append("--portrait")

    log = f"ğŸ‹ï¸ å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼š{user_id}\n"

    try:
        p = Popen(cmd, stdout=PIPE, stderr=PIPE, text=True)
        for line in p.stdout:
            log += line
            yield log, gr.update()
        p.wait()
        if p.returncode != 0:
            raise Exception("è®­ç»ƒå¤±è´¥")
    except Exception as e:
        log += f"\nâŒ é”™è¯¯ï¼š{e}"
        yield log, gr.update()
        return

    log += "\nâœ… è®­ç»ƒå®Œæˆ âœ…"
    yield log, gr.update(choices=list_model_names(), value=f"trial_{user_id}")

# ========== éŸ³é¢‘è½¬ WAV ==========
def convert_to_wav(input_file):
    if not input_file:
        return None, "âŒ è¯·ä¸Šä¼ ä¸€ä¸ªéŸ³/è§†é¢‘æ–‡ä»¶"

    tmp_output = os.path.join(tempfile.gettempdir(), f"{uuid.uuid4()}.wav")
    command = [
        "ffmpeg", "-y",
        "-i", input_file,
        "-ar", "16000",
        "-ac", "1",
        tmp_output
    ]

    try:
        subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return tmp_output, "âœ… è½¬æ¢æˆåŠŸ"
    except Exception as e:
        return None, f"âŒ è½¬æ¢å¤±è´¥ï¼š{e}"

# ========== é¡µé¢åŠ è½½æ—¶åˆ·æ–° ==========
def refresh_model_dropdown():
    return gr.update(choices=list_model_names(), value=list_model_names()[0] if list_model_names() else None)

def refresh_id_dropdown():
    return gr.update(choices=list_processed_ids(), value=list_processed_ids()[0] if list_processed_ids() else None)

# ========== Gradio UI ==========
with gr.Blocks() as demo:
    gr.Markdown("# ğŸŒ± æ–°è‹—è®¡åˆ’å¹³å° - åˆ†æ­¥è®­ç»ƒä¸ç”Ÿæˆ")

    # ========== è¯­éŸ³ç”Ÿæˆ ==========
    gr.Markdown("## ğŸ§ ä¸Šä¼ è¯­éŸ³ç”Ÿæˆè§†é¢‘")

    model_dropdown = gr.Dropdown(label="é€‰æ‹©äººç‰©æ¨¡å‹", choices=[], value=None)
    reference_image = gr.Image(label="è‡ªåŠ¨é€‰å–çš„å‚è€ƒå›¾", height=240)

    model_dropdown.change(fn=update_reference_image, inputs=model_dropdown, outputs=reference_image)

    with gr.Row():
        audio_input = gr.Audio(type="filepath", label="ä¸Šä¼ éŸ³é¢‘ï¼ˆ.wavï¼‰")

    with gr.Row():
        run_btn = gr.Button("ğŸ¬ å¼€å§‹ç”Ÿæˆ")
        clear_btn = gr.Button("ğŸ§¹ æ¸…ç©ºæ—¥å¿—")

    status_box = gr.Textbox(label="ç”Ÿæˆæ—¥å¿—è¾“å‡º", lines=12, interactive=False)
    video_output = gr.Video(label="ç”Ÿæˆçš„è§†é¢‘", height=360)

    run_btn.click(
        fn=process_audio_with_log,
        inputs=[audio_input, model_dropdown],
        outputs=[status_box, video_output]
    )

    clear_btn.click(
        fn=lambda: ("", None),
        outputs=[status_box, video_output]
    )


    gr.Markdown("---")

    # ========== æ­¥éª¤ä¸€ï¼šå¤„ç†æ•°æ® ==========
    gr.Markdown("## ğŸ§© ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ è§†é¢‘å¹¶å¤„ç†æ•°æ®")

    with gr.Row():
        raw_video = gr.Video(label="ä¸Šä¼ åŸå§‹è§†é¢‘ (.mp4)")
        input_id = gr.Textbox(label="äººç‰© IDï¼ˆä¾‹å¦‚ jkxï¼‰", placeholder="åªèƒ½æ˜¯è‹±æ–‡å­—æ¯æˆ–æ•°å­—")

    process_btn = gr.Button("ğŸ“¦ å¤„ç†è§†é¢‘ç”Ÿæˆæ•°æ®")
    process_log = gr.Textbox(label="å¤„ç†æ—¥å¿—", lines=8, interactive=False)
    process_btn.click(fn=handle_data_processing_with_log, inputs=[raw_video, input_id], outputs=[process_log])

    gr.Markdown("---")

    # ========== æ­¥éª¤äºŒï¼šè®­ç»ƒæ¨¡å‹ ==========
    gr.Markdown("## ğŸ‹ï¸ ç¬¬äºŒæ­¥ï¼šè®­ç»ƒæ¨¡å‹")

    with gr.Row():
        id_dropdown = gr.Dropdown(label="é€‰æ‹©å·²å¤„ç†æ•°æ® ID", choices=[])
        portrait_cb = gr.Checkbox(label="ä½¿ç”¨äººè„¸æ¨¡å¼", value=False)

    train_btn = gr.Button("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹")
    train_log = gr.Textbox(label="è®­ç»ƒæ—¥å¿—è¾“å‡º", lines=12, interactive=False)

    train_btn.click(fn=train_model, inputs=[id_dropdown, portrait_cb], outputs=[train_log, model_dropdown])

    gr.Markdown("---")

    # ========== é™„åŠ åŠŸèƒ½ï¼šè½¬ä¸º WAV ==========
    gr.Markdown("## ğŸ¼ è½¬æ¢ä¸º WAV æ ¼å¼")

    with gr.Row():
        input_audio_file = gr.File(label="ä¸Šä¼ éŸ³é¢‘/è§†é¢‘æ–‡ä»¶ï¼ˆä»»æ„æ ¼å¼ï¼‰")
        convert_btn = gr.Button("ğŸµ è½¬æ¢ä¸º .wav")

    with gr.Row():
        wav_output = gr.File(label="è½¬æ¢åçš„ WAV æ–‡ä»¶")
        convert_status = gr.Textbox(label="è½¬æ¢çŠ¶æ€", interactive=False)

    convert_btn.click(
        fn=convert_to_wav,
        inputs=input_audio_file,
        outputs=[wav_output, convert_status]
    )

    # é¡µé¢åˆå§‹åŒ–
    demo.load(fn=refresh_model_dropdown, outputs=model_dropdown)
    demo.load(fn=refresh_id_dropdown, outputs=id_dropdown)

demo.launch()
